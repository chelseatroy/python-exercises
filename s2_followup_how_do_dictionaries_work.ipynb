{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2addf09c-ce82-4c96-951d-da8511eed33a",
   "metadata": {},
   "source": [
    "# How do Dictionaries Work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e185ba98-873a-44ab-bbda-08b911b32618",
   "metadata": {},
   "outputs": [],
   "source": [
    "niceties = {\"greeting\" : \"Hello\", \"departing\" : \"Goodbye\", \"requesting\" : \"please\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86231a43-7247-48cb-8497-f01b8cfd6e5d",
   "metadata": {},
   "source": [
    "## 1. Load Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8ffe82a-9603-41c2-b690-0ce2c1565662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize at 0 entries: size of underlying array changed from 64 → 232 bytes\n",
      "Resize at 5 entries: size of underlying array changed from 232 → 360 bytes\n",
      "Resize at 10 entries: size of underlying array changed from 360 → 640 bytes\n",
      "Resize at 21 entries: size of underlying array changed from 640 → 1176 bytes\n",
      "Resize at 42 entries: size of underlying array changed from 1176 → 2272 bytes\n",
      "Resize at 85 entries: size of underlying array changed from 2272 → 4696 bytes\n",
      "Resize at 170 entries: size of underlying array changed from 4696 → 9312 bytes\n",
      "Resize at 341 entries: size of underlying array changed from 9312 → 18520 bytes\n",
      "Resize at 682 entries: size of underlying array changed from 18520 → 36960 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "d = {}\n",
    "prev_size = sys.getsizeof(d)\n",
    "\n",
    "for i in range(1000):\n",
    "    d[i] = i\n",
    "    bytes_of_data = bytes_of_data + sys.getsizeof(d[i]) + sys.getsizeof(i)\n",
    "        \n",
    "    new_size = sys.getsizeof(d)\n",
    "    if new_size != prev_size:\n",
    "        print(f\"Resize at {i} entries: size of underlying array changed from {prev_size} → {new_size} bytes\")\n",
    "        prev_size = new_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25650b-4b04-4b00-8ca8-371ac6fb0b88",
   "metadata": {},
   "source": [
    "We face a tradeoff with selecting the load factor and resize strategy because the lower the load factor and the more we resize by, the more space the dict takes up in memory that maybe it won't need for actual entries. \n",
    "\n",
    "But a higher load factor means more dealing with collisions before a resize, which can make reads and writes slower, and the less we resize by, the more often we have to do the resize operation...which makes writes slower also, as the whole dict now has to be transferred to a larger table before the write that triggered the resize is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2477f3-a8b5-4209-82da-9d73afac67e8",
   "metadata": {},
   "source": [
    "## 2. Hashing the Keys\n",
    "\n",
    "A good hash function is: \n",
    "\n",
    "1. Deterministic\n",
    "2. Uniform\n",
    "3. Fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f26b6-6bdb-4d22-961a-6f2542a18e1f",
   "metadata": {},
   "source": [
    "# [--------] [--------] [--------] [--------] [--------] [--------] [--------] [--------] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0437b21-13da-4a0b-a062-52308d3f0811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901722735092097552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"greeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b8ce770-f9ea-41bd-a282-07f3449068ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"greeting\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae24634-bd60-4a1e-b12c-8be34363d29c",
   "metadata": {},
   "source": [
    "# [\"greeting\"] [--------]  [--------] [--------] [--------] [--------] [--------] [--------] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a255d371-dcf9-4ad0-856d-d39ed62057d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"departing\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676aa619-471a-4580-bc42-2fe3e9b0b98b",
   "metadata": {},
   "source": [
    "# [\"greeting\"] [-------] [-------] [-------] [\"departing\"] [-------] [-------] [-------] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c91d1b-decb-4c39-8391-2b8885bb39c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"requesting\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ecedf8-65ac-4fdc-96df-44b63110ec7a",
   "metadata": {},
   "source": [
    "# [\"greeting\"] [------] [------] [------] [\"departing\"] [\"requesting\"] [------] [------] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10435e2c-e65d-4a6a-900a-4f184ee320d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"thanking\") % 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d334a3-023b-4fbc-a0de-a8e27b6d52c9",
   "metadata": {},
   "source": [
    "## 3. Separate Chaining vs Open Addressing and Probing\n",
    "\n",
    "This would be separate chaining. This is what Java, Go, C#, and C++ does.\n",
    "\n",
    "# [\"greeting\"][-----][-----] [-----] [\"departing\"] [\"requesting\"] [-----] [-----] \n",
    "# ---- v ---\n",
    "# [\"thanking\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080792b-7b94-4da3-b555-8aedb387ec25",
   "metadata": {},
   "source": [
    "Open addressing with probing is what Python, Ruby, and Rust all do.\n",
    "\n",
    "Now, the below demonstrates open addressing with straight linear probing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fbf0f-06c6-4956-b461-051eb9acb79e",
   "metadata": {},
   "source": [
    "# [\"greeting\"] [\"thanking\"] [-----] [-----] [\"departing\"] [\"requesting\"] [-----] [-----] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e2d0d55-70b2-4107-9e26-a6167944aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"apologizing\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be017a42-ebe6-4df9-b60c-500e47b8cae0",
   "metadata": {},
   "source": [
    "Now, linear probing is not exactly what Python does, because linear probing tends to result in a bunch of overflowing buckets right next to each other, which, like separate chaining, approaches O(n) efficiency the worse it gets. Instead, when a Python dictionary encounters a hash collision, it uses the original hash value to determine the next index to visit. \n",
    "\n",
    "Now, it _doesn't_ exactly hash the original hashed value (though you _could_). It might instead be something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ff0788-fbeb-44e8-a389-2c01e9621cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb = hash(\"apologizing\") # This is NOT exactly how the perturb is calculated—the details are a bit more complicated—but it does _use_ the original hash\n",
    "current_index = hash(\"apologizing\") % 8\n",
    "new_value_including_original_hash = current_index * 5 + perturb + 1 \n",
    "new_value_including_original_hash % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c30b5-75ad-4ef8-b79c-52804e507a87",
   "metadata": {},
   "source": [
    "# [\"greeting\"] [\"thanking\"] [--] [--] [\"departing\"] [\"requesting\"] [\"apologizing\"] [--] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b682029f-6329-4db2-8530-79a12adea746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"purchasing\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa5dcc-10c0-4080-9dc0-7d7f49c295c6",
   "metadata": {},
   "source": [
    "## [\"greeting\"] [\"thanking\"] [--] [--] [\"departing\"] [\"requesting\"] [\"apologizing\"] [\"purchasing\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbfba6-79f6-4e76-93bc-a81030a317fd",
   "metadata": {},
   "source": [
    "Here, more than 2/3rds of the entries are full, and this is CPython's default load factor. \n",
    "\n",
    "At this point, Python increases the size of the array. The way it does this is....\n",
    "\n",
    "1. It multiplies the number of FILLED entries by 3 (so in this case, 6 * 3 is 18)\n",
    "2. It rounds up to the nearest power of 2 (it does this because...sigh....okay it _does this_ because bitmasking and bitshifting are much faster operations for doing multiplication and division operations in C than actual multiplication and division are, but you need a binary digit to use them. It makes a big enough difference to the speed of Python to be worth the extra space allocated this way.) In this case that's gonna be 32 entries now, because 2 ** 4 is only sixteen and the next one up is 2 ** 5. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5ba9d-a547-4508-a4f9-42edfafb2d3b",
   "metadata": {},
   "source": [
    "# 4. Tombstones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af36a6-5073-4719-83ed-a1813c22249f",
   "metadata": {},
   "source": [
    "A _tombstone_ is a value that we use to replace a deleted value. Right now in our example above, if we delete \"greeting\" and leave that slot empty...\n",
    "\n",
    "# [--] [\"thanking\"] [--] [--] [\"departing\"] [\"requesting\"] [\"apologizing\"] [--] \n",
    "\n",
    "...and then we try to find \"thanking\", we do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3829b1a-a482-47dd-81ee-2e8c5e515299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"thanking\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1b4dc-6a28-4ab2-a66d-e2c28326dae3",
   "metadata": {},
   "source": [
    "and go to the first spot in the table, and see _nothing there_. The way we find values in the table is we _walk from their original hash index along the probing sequence until we either find them, or we find an empty slot...at which point the language assumes it's _not there_ (maybe it has been deleted, for example). But this one HAS NOT been deleted. It's just that the probing sequence has a deleted element. SO instead we do...\n",
    "\n",
    "# [TOMBSTONE] [\"thanking\"] [--] [--] [\"departing\"] [\"requesting\"] [\"apologizing\"] [--] \n",
    "\n",
    "This leaves the probe chain intact for us to follow to find \"thanking\" after all :)\n",
    "\n",
    "Note that tombstones are a detail of the underlying implementation of the open addressing protocol because there's no structural difference between an entry that required probing to be placed and an entry that didn't. If you use separate chaining and you store the entries in linked lists, you can delete a thing from a linked list and stitch the two sides of the list back together (in fact, this is what linked lists are for) and it'll work. Your one issue there would be deleting the FIRST item in the linked list; rather than then leave that spot empty, since it's the entry point, you either have to move the formerly-second-now-first item into that spot, or you have to do a tombstone there. As with other tombstones, you can remove it when you resize the underlying table and then reenter all the entries into the new table. \n",
    "\n",
    "\"Tombstone\" is a word we tend to use in programming to describe any strategy in which we do something _other than deletion_ upon the end user asking to delete something, usually to make the program run the way the user expects after the deletion. You have to do something like this in your homework to handle a user deleting a key in a transaction because you cannot tell the main data store to remove a key just by not having that key in the update store. You have to devise some way to indicate that a column is supposed to be deleted, either by making a list of column names to delete upon commission or setting the value of the key in the update table to a sentinel value like \"DELETEME123.\" This second strategy, while not requiring a new data structure like the first strategy, runs the risk of colliding with a user _actually_ wanting to set a column to whatever the sentinel value is, but you can choose a sentinel value that's really, really unlikely (for example, given that columns are represented with lists, a string like \"DELETEME123\" is very unlikely to be _intentionally_ set by a user). Though this strategy looks primitive, it was ACTUALLY part of the fabric of the original implementation of Facebook's Cassandra project for darge data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda7604-a5c2-4d44-bb8c-8ac5bb29dd46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
