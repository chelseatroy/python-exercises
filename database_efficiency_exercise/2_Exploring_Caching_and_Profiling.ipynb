{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's explore caching and profiling.\n",
    "\n",
    "Important words: \n",
    "\n",
    "**caching** - Saving a piece of information, usually one that is computationally expensive to fetch, in fast-access memory to hand out to clients who ask for that piece of information. Usually done after the first time the piece of info is fetched. When the result of a function is cached for a specific set of arguments to the function, it's called **memoization**.\n",
    "\n",
    "**profiling** - Running our code with a tool that tells us how much time and/or memory each portion of our code is using. It is (or should be) the first step in any serious code optimization effort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In REAL LIFE the module you'll import this from is called functools.\n",
    "# In this version, I deliberately patched lru_cache to give you access to the cache,\n",
    "# Which you don't get in the \"real\" version for thread safety reasons.\n",
    "from chelseas_functools import lru_cache \n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have written a recursive function that calculates the _factorial_ of a number.\n",
    "\n",
    "Example: 5 factorial, or 5!, is 5 * 4 * 3 * 2 * 1, or 120.\n",
    "\n",
    "I have decorated it with the `@lru_cache` decorator with a `maxsize` argument of `None`.\n",
    "\n",
    "[Theis documentation](https://docs.python.org/3/library/functools.html) covers how `@lru_cache` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def factorial(num):\n",
    "    if num == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return num * factorial(num-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I run my factorial function on the number 50 with Python's profiler. [Here is the documentation](https://docs.python.org/3/library/profile.html) on how to read profiler output.\n",
    "\n",
    "Run the cell below a couple of times and notice how the profiler output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 chelseas_functools.py:458(_make_key)\n",
      "        1    0.000    0.000    0.000    0.000 chelseas_functools.py:561(wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('factorial(51)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@lru_cache` decorator adds two methods to the `factorial` function:\n",
    "    \n",
    "1. `cache_info`, which gives you four pieces of information about the cache (what are they?)\n",
    "1. `cache_clear`, which clears the cache so you can run the function \"from scratch\" again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CacheInfo(hits=1, misses=51, maxsize=None, currsize=51)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial.cache_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, so here's where I did something naughty.\n",
    "\n",
    "I augmented the `@lru_cache` wrapper to give you access to the cache. DO NOT USE the `chelseas_functools` version of `@lru_cache` in any production application. But for our _educational_ purposes, you can here peek inside the cache that the function is keeping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 2,\n",
       " 3: 6,\n",
       " 4: 24,\n",
       " 5: 120,\n",
       " 6: 720,\n",
       " 7: 5040,\n",
       " 8: 40320,\n",
       " 9: 362880,\n",
       " 10: 3628800,\n",
       " 11: 39916800,\n",
       " 12: 479001600,\n",
       " 13: 6227020800,\n",
       " 14: 87178291200,\n",
       " 15: 1307674368000,\n",
       " 16: 20922789888000,\n",
       " 17: 355687428096000,\n",
       " 18: 6402373705728000,\n",
       " 19: 121645100408832000,\n",
       " 20: 2432902008176640000,\n",
       " 21: 51090942171709440000,\n",
       " 22: 1124000727777607680000,\n",
       " 23: 25852016738884976640000,\n",
       " 24: 620448401733239439360000,\n",
       " 25: 15511210043330985984000000,\n",
       " 26: 403291461126605635584000000,\n",
       " 27: 10888869450418352160768000000,\n",
       " 28: 304888344611713860501504000000,\n",
       " 29: 8841761993739701954543616000000,\n",
       " 30: 265252859812191058636308480000000,\n",
       " 31: 8222838654177922817725562880000000,\n",
       " 32: 263130836933693530167218012160000000,\n",
       " 33: 8683317618811886495518194401280000000,\n",
       " 34: 295232799039604140847618609643520000000,\n",
       " 35: 10333147966386144929666651337523200000000,\n",
       " 36: 371993326789901217467999448150835200000000,\n",
       " 37: 13763753091226345046315979581580902400000000,\n",
       " 38: 523022617466601111760007224100074291200000000,\n",
       " 39: 20397882081197443358640281739902897356800000000,\n",
       " 40: 815915283247897734345611269596115894272000000000,\n",
       " 41: 33452526613163807108170062053440751665152000000000,\n",
       " 42: 1405006117752879898543142606244511569936384000000000,\n",
       " 43: 60415263063373835637355132068513997507264512000000000,\n",
       " 44: 2658271574788448768043625811014615890319638528000000000,\n",
       " 45: 119622220865480194561963161495657715064383733760000000000,\n",
       " 46: 5502622159812088949850305428800254892961651752960000000000,\n",
       " 47: 258623241511168180642964355153611979969197632389120000000000,\n",
       " 48: 12413915592536072670862289047373375038521486354677760000000000,\n",
       " 49: 608281864034267560872252163321295376887552831379210240000000000,\n",
       " 50: 30414093201713378043612608166064768844377641568960512000000000000,\n",
       " 51: 1551118753287382280224243016469303211063259720016986112000000000000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many items are in this cache? Is that how many items you expected this cache to have in there?\n",
    "\n",
    "Does this cache **remind** you of any in-class exercises we have done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try out @lru_cache with a maxsize.\n",
    "\n",
    "So far in this exercise, we have had the `@lru_cache`'s `maxsize` argument set to `None`. This means that the cache increases in size _indefinitely_. Python has another decorator called `@cache` that has the same behavior as `@lru_cache` with a `maxsize` set to `None`.\n",
    "\n",
    "#### Questions for you:\n",
    "\n",
    "1. Based on the documentation you read, what is the default value for `maxsize` in `@lru_cache`?\n",
    "2. What are the units of `maxsize`? What is it saving that many of?\n",
    "\n",
    "Let's set the `@lru_cache`'s `maxsize` to something else: ten, for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=10)\n",
    "def factorial(num):\n",
    "    if num == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return num * factorial(num-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run our wrapped function on a number (I have deliberately chosen a small number to make the following examples easier to visually inspect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's where things get wild**: observe below how the data structure used for the cache _changes_ when the cache has a `maxsize`. \n",
    "\n",
    "What data structure is that?\n",
    "Why do you think it's getting used here? \n",
    "\n",
    "**Hint #1:** When `@lru_cache` has a limited size, how does it decide which items to keep and which items to get rid of? Does the data structure we saw above support that use case?\n",
    "\n",
    "**Hint #2:** you can go _look_ at the actual, _real_ implementation of `lru_cache` [right here](https://github.com/python/cpython/blob/main/Lib/functools.py)â€”or even my copied version in the `chelseas_functools` module in this directory, which is _almost exactly_ the same as the real implementation. Search in the file for `def _lru_cache_wrapper`, which (shocking!) defines the `lru_cache` wrapper. See how that function _switches_ how it implements the cache based on the `maxsize` argument?\n",
    "\n",
    "Here's what the cache looks like when it has a `maxsize`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [[[[[...], [...], 2, 2], [...], 3, 6], [...], None, None],\n",
       "  [[...], [[...], [[...], [...], None, None], 3, 6], 2, 2],\n",
       "  1,\n",
       "  1],\n",
       " 2: [[[[[...], [...], 3, 6], [...], None, None], [...], 1, 1],\n",
       "  [[...], [[...], [[...], [...], 1, 1], None, None], 3, 6],\n",
       "  2,\n",
       "  2],\n",
       " 3: [[[[[...], [...], None, None], [...], 1, 1], [...], 2, 2],\n",
       "  [[...], [[...], [[...], [...], 2, 2], 1, 1], None, None],\n",
       "  3,\n",
       "  6]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id(factorial.cache[1][1]) == id(factorial.cache[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
